 
<!DOCTYPE html>
<html lang="en">
<head class="include" file="../include/header.html">
<link rel="stylesheet" href="../include/bootstrap.min.css">
<link rel="stylesheet" href="../include/bootstrap-theme.min.css">
<link rel="stylesheet" href="../include/bootstrap-select.min.css">
<link rel="stylesheet" href="../include/style.css" type="text/css">
<link rel="stylesheet" href="../include/highlight.css" type="text/css">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta NAME="keywords" CONTENT="reproducible, research, platform, rrp, rr, reproducible research, reproducible research platform, matlab, code, mat2doc, science, knowledge"/>

<title>ADAPTATED_SAMPLING - Adaptation of the sampling according to local uncertainy</title>
</head>



<!-- body must stay hidden until all include parts are loaded -->
<body style="display:none;">
<!-- Wrap the content into responsive container -->
<div class="container">
<!-- Include main navigation -->
    <div class="masthead include" file="../include/mainnav.html"></div>
        <div class="row">
            <div class="col-md-2" id="codeswitch"><div id="menutitle"><a href="adaptated_sampling_code.html">View the code</a></div>
</div>
            <div class="btn btn-large btn-success span22-doc">
                <a style="color: #FFFFFF" href="../archive/#PACKAGE#.zip">Download <font color="red">r<sup>2</sup>&pi;</font> archive for windows</a>
                <a style="color: #FFFFFF" href="../archive/#PACKAGE#.tgz"> or for unix </a> 
            </div>
        </div>
        <div class="row">
            <div class="col-md-2">
                <div class="include" file='contentsmenu.html'></div>
                <br/>
                <div id="seealso"><p></p></div>
                <br/>
            </div>
            <div class="col-md-10">
           
                    <h1 class="title">ADAPTATED_SAMPLING - Adaptation of the sampling according to local uncertainy</h1>

<div class="section" id="xxxdescription">
<h2>Description</h2>
<p>This package contains the code to reproduce all the figures of the
paper:</p>
<p>Global and Local Uncertainty Principles for Signals on Graphs</p>
<p>Authors: Nathanael Perraudin, Benjamin Ricaud, David I Shuman, Pierre
Vandergheynst</p>
<p>ArXiv: <a class="reference external" href="http://arxiv.org/abs/1603.03030">http://arxiv.org/abs/1603.03030</a></p>
</div>
<div class="section" id="abstract-of-the-paper">
<h2>Abstract of the paper</h2>
<p>Uncertainty principles such as Heisenberg's provide limits on the
time-frequency concentration of a signal, and constitute an important
theoretical tool for designing and evaluating linear signal transforms.
Generalizations of such principles to the graph setting can inform
dictionary design for graph signals, lead to algorithms for
reconstructing missing information from graph signals via sparse
representations, and yield new graph analysis tools. While previous
work has focused on generalizing notions of spreads of a graph signal
in the vertex and graph spectral domains, our approach is to generalize
the methods of Lieb in order to develop uncertainty principles that
provide limits on the concentration of the analysis coefficients of any
graph signal under a dictionary transform whose atoms are jointly
localized in the vertex and graph spectral domains. One challenge we
highlight is that due to the inhomogeneity of the underlying graph data
domain, the local structure in a single small region of the graph can
drastically affect the uncertainty bounds for signals concentrated in
different regions of the graph, limiting the information provided by
global uncertainty principles. Accordingly, we suggest a new way to
incorporate a notion of locality, and develop local uncertainty
principles that bound the concentration of the analysis coefficients of
each atom of a localized graph spectral filter frame in terms of
quantities that depend on the local structure of the graph around the
center vertex of the given atom. Finally, we demonstrate how our
proposed local uncertainty measures can improve the random sampling of
graph signals.</p>
</div>
<div class="section" id="this-experiment">
<h2>This experiment</h2>
<p>In order to motivate our uncertainty Theorem from a practical signal
processing point of view, we use it to optimize the sampling of a
signal over a graph. To asses the quality of the sampling, we solve a
small inpainting problem where only a part of a signal is measured and
the goal is to reconstruct the entire signal. Assuming that the signal
varies smoothly in the vertex domain, we can formulate the inverse
problem as:</p>
<!-- argmin_x  x^T L x      s. t.    y = Mx, -->
<div class="math">
\begin{equation*}
\mathop{\rm argmin}_x  x^T L x \hspace{0.25cm} \text{ s. t. } \hspace{0.25cm} y = Mx,
\end{equation*}
</div>
<p>where <span class="math">\(y\)</span> is the observed signal, <span class="math">\(M\)</span> the inpainting masking operator
and <span class="math">\(x^T L x\)</span> the graph Tikhonov regularizer (<span class="math">\(L\)</span> being the
Laplacian). In order to generate the original signal, we filter
Gaussian noise on the graph with a low pass kernel <span class="math">\(\hat{h}\)</span>. The
frequency content of the resulting signal will be close to the shape of
the filter <span class="math">\(\hat{h}\)</span>. For this example, we use the low pass kernel
<span class="math">\(\hat{h}(x) = \frac{1}{1+\frac{100}{\lambda_{\max}} x}\)</span> to generate the
smooth signal.</p>
<p>For a given number of measurements, the traditional idea is to randomly
sample the graph. Under that strategy, the measurements are distributed
across the network. Alternatively, we can use our local uncertainty
principles to create an adapted mask. The intuitive idea that nodes
with less uncertainty (higher local sparsity values) should be sampled
with higher probability because their value can be inferred less easily
from other nodes. Another way to picture this fact is the following.
Imagine that we want to infer a quantity over a random sensor network.
In the more densely populated parts of the network, the measurements
are more correlated and redundant. As result, a lower sampling rate is
necessary. On the contrary, in the parts where there are fewer sensors,
the information has less redundancy and a higher sampling rate is
necessary. The heat kernel <span class="math">\(\hat{g}(x)=e^{-\tau x}\)</span> is a convenient
choice to probe the local uncertainty of a graph, because
<span class="math">\(\hat{g}^{2}(x)=e^{-2\tau~x}\)</span> is also a heat kernel, resulting in a
sparsity level depending only on <span class="math">\(\|T_{j}g^{2}\|_{2}\)</span>. Indeed we have
<span class="math">\(||T_{j}g^{2}||_{1}=\sqrt{N}\)</span>. The local uncertainty bound of our
Theorem becomes:</p>
<!-- O_{1}(j)= || T_j g^2 ||_1 / || T_j g^2 ||_2 =
= \sqrt{N} / || T_j g^2 ||_2. -->
<div class="math">
\begin{equation*}
O_{1}(j)=\frac{\|T_{j}g^{2}\|_{1}}{\|T_{j}g^{2}\|_{2}}=\frac{\sqrt{N}}{\|T_{j}g^{2}\|_{2}}.
\end{equation*}
</div>
<p>Based on this measure, we design a second random sampled mask with a
probability proportional to <span class="math">\(||T_ig^2||_2\)</span>; that is, the higher the
overlap level at vertex <span class="math">\(j\)</span>, the smaller the probability that vertex
<span class="math">\(j\)</span> is chosen as a sampling point, and vice-versa. For each sampling
ratio, we performed <span class="math">\(100\)</span> experiments and averaged the results. For
each experiment, we also randomly generated new graphs. The experiment
was carried out using open-source code: the UNLocBoX and the GSPBox.</p>
<p>For the sensor graph, we observe that our local measure of uncertainty
varies smoothly on the graph and is higher in the more dense part.
Thus, the likelihood of sampling poorly connected vertices is higher
than the likelihood of sampling well connected vertices. For the
community graph, we observe that the uncertainty is highly related to
the size of the community. The larger the community, the larger the
uncertainty (or, equivalently, the smaller the local sparsity value).
In both cases, the adapted, non-uniform random sampling performs better
than random uniform sampling.</p>
<div class="figure align-center">
<img alt="adaptated_sampling_1.png" src="adaptated_sampling_1.png" />
<p class="caption">Reconstructions resulting</p>
<div class="legend">
Non uniform sampling performs better</div>
</div>
<div class="figure align-center">
<img alt="adaptated_sampling_2.png" src="adaptated_sampling_2.png" />
<p class="caption">Local uncertainty</p>
<div class="legend">
The local uncertainty is inversly proportional to <span class="math">\(||T_i g||_2\)</span>.</div>
</div>
<div class="figure align-center">
<img alt="adaptated_sampling_3.png" src="adaptated_sampling_3.png" />
<p class="caption">Norm of the atoms</p>
<div class="legend">
The random non-uniform sampling distribution is proportional to
<span class="math">\(||T_i g||_2\)</span>.</div>
</div>
<p><em>This code produces the following output</em>:</p>
<pre class="literal-block">
Relative error adaptated sampling: 0.308
Relative error random sampling: 0.325
</pre>
</div>
<H2>References:</H2>



<p><a name="perraudin2016global"></a>

N.&nbsp;Perraudin, R.&nbsp;Benjamin, S.&nbsp;David&nbsp;I, and P.&nbsp;Vandergheynst.
 Global and local uncertainty principles for signals on graphs.
 <em>arXiv preprint arXiv:1603.03030</em>, 2016.

</p>


            </div>
        </div>

        <div class="include" file="../include/footer.html"></div>
    </div>
</div>
<!-- These two have to be here to dynamically load the included parts -->
<script src="../include/jquery.min.js"></script>
<script src="../include/bootstrap-select.min.js"></script>
<script src="../include/rrp.js" type="text/javascript"></script>
</body>
</html>




